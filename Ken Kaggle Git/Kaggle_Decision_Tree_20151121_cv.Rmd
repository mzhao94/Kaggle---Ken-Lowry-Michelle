---
title: "Kaggle_Decision_Tree_20151121"
author: "Ken Calhoon"
date: "October 16, 2015"
output: html_document
---

####Prepping data
```{r}
#setwd("/Users/Lowry/Documents/Stanford/Senior/Fall/Stats_202/Data_Directory")
setwd("~/Dropbox/Stats202/Kaggle")
training.features <- read.csv(file="training_features.csv", header=TRUE, sep=",")
training.target <- read.csv(file="training_target.csv",header=TRUE, sep=",")
feature.names <- names(training.features) # Create vector of feature names
num.col.nas <- 0
for (feature.name in feature.names[-1]) {
                    # Give the new dummy variable a meaningful name
                    dummy.name <- paste0("is.na.",feature.name)
                    is.na.feature <- is.na(training.features[,feature.name])
                    num.col.nas[feature.name] = sum(is.na(training.features[,feature.name]))
                    # Convert boolean values to binary
                    training.features[,dummy.name] <- as.integer(is.na.feature)
                    # Replace NA with median value for each column
                    training.features[is.na.feature,feature.name] <- median(training.features[,feature.name], na.rm = TRUE)
}
dim.data.frame(training.features) # Confirms dimension of new dataframe
#merged.data=merge(training.target,training.features,by="subject.id") # creates one DF with ALSFRS_slope (response variable) as column 2
feature.nas=c(num.col.nas,num.col.nas[-1]) # creates double wide vector for original and boolean variables
sum(num.col.nas)
```

Column 1: subject.id columns 2:858 original training.feature columns, with NAs replaced with median value columns 859-1715 new dummy columns named "is.na.[original column_name]"
```{r}
leaderboard.predictions <- read.csv(file = "leaderboard_predictions-example.csv", header=TRUE, sep=",")
leaderboard.features <- read.csv(file="leaderboard_features.csv", header=TRUE, sep=",")
feature.names <- names(leaderboard.features) # Create vector of feature names
num.col.nas.lead <- 0
for (feature.name in feature.names[-1]) {
                    # Give the new dummy variable a meaningful name
                    dummy.name <- paste0("is.na.",feature.name)
                    is.na.feature <- is.na(leaderboard.features[,feature.name])
                    num.col.nas[feature.name] = sum(is.na(leaderboard.features[,feature.name]))
                    # Convert boolean values to binary
                    leaderboard.features[,dummy.name] <- as.integer(is.na.feature)
                    # Replace NA with median value for each column
                    leaderboard.features[is.na.feature,feature.name] <- median(leaderboard.features[,feature.name],
                    na.rm = TRUE)
}
dim.data.frame(leaderboard.features) # Confirms dimension of new dataframe
leader.nas=c(num.col.nas,num.col.nas[-1])# creates double wide vector for original and boolean variables
sum(num.col.nas)
```

```{r}
validation.target <- read.csv(file = "validation_target.csv", header=TRUE, sep=",")
validation.features <- read.csv(file="validation_features.csv", header=TRUE, sep=",")
feature.names <- names(validation.features) # Create vector of feature names
num.col.nas.lead <- 0
for (feature.name in feature.names[-1]) {
                    # Give the new dummy variable a meaningful name
                    dummy.name <- paste0("is.na.",feature.name)
                    is.na.feature <- is.na(validation.features[,feature.name])
                    num.col.nas[feature.name] = sum(is.na(validation.features[,feature.name]))
                    # Convert boolean values to binary
                    validation.features[,dummy.name] <- as.integer(is.na.feature)
                    # Replace NA with median value for each column
                    validation.features[is.na.feature,feature.name] <- median(validation.features[,feature.name],
                    na.rm = TRUE)
}
dim.data.frame(validation.features) # Confirms dimension of new dataframe
validation.nas=c(num.col.nas,num.col.nas[-1]) # creates double wide vector for original and boolean variables
sum(num.col.nas)
```

______________________________________________________________

###Adjust "filter.ratio" below to adjust level of NAs screened out. Variables then screened out based on this. Portion of NAs must be lower than ratio to be included. 1.0 leaves all variables intact

```{r}
#adjust filter ratio to screen 
filter.ratio=.9 #NAs must be less than this ratio for the variable to be kept
#creates vector filter: true mean keep the variable based on filter ratio above
variable.filter=as.logical((feature.nas<=nrow(training.features)*filter.ratio) & (leader.nas<=nrow(leaderboard.features)*filter.ratio) & (validation.nas<=nrow(validation.features)*filter.ratio))
training.feat.subset=training.features[,variable.filter]
leaderboard.feat.subset=leaderboard.features[,variable.filter]
validation.feat.subset=validation.features[,variable.filter]

#creates full dataframes with target as second variable
training.subset.with.target=merge(training.target,training.feat.subset,by="subject.id")
validation.subset.with.target=merge(validation.target,validation.feat.subset,by="subject.id")

```


# Use below to eliminate boolean "isna" columns is desired

```{r}
ncols=ncol(training.subset.with.target)
training.subset.with.target=training.subset.with.target[,-c((ncols/2+2):ncols)]
validation.subset.with.target=validation.subset.with.target[,-c((ncols/2+2):ncols)]
leaderboard.feat.subset=leaderboard.feat.subset[,-c((ncols/2+1):ncols)]
```

______________________________________________________________

####Lasso Model. Uses data created above. 

####Decision tree
```{r}

library(tree)
set.seed(1)
train.size=.8
merged.data.subset=training.subset.with.target
train=sample(1:nrow(merged.data.subset),nrow(merged.data.subset)*train.size)
test=-train
k.tree=tree(ALSFRS_slope~.,merged.data.subset[train,])

cv.k.tree=cv.tree(k.tree,FUN=prune.tree)
names(cv.k.tree)
cv.k.tree
par(mfrow=c(1,2))
plot(cv.k.tree$size,cv.k.tree$dev,type="b")
plot(cv.k.tree$k,cv.k.tree$dev,type="b")
prune.k.tree=prune.tree(k.tree,best=which.min(cv.k.tree$dev))
plot(prune.k.tree)
text(prune.k.tree,pretty=0)
summary(prune.k.tree)

tree.predict=predict(prune.k.tree,newdata=merged.data.subset[test,])
plot(merged.data.subset$ALSFRS_slope[test],tree.predict)
abline(0,1)
test.rmse=mean((merged.data.subset$ALSFRS_slope[test]-tree.predict)^2)^.5
test.rmse

#Validation RMSE
valid.predict=predict(prune.k.tree,newdata=validation.feat.subset)
valid.rmse=mean((validation.target$ALSFRS_slope-valid.predict)^2)^.5
valid.rmse

#calculate leaderboard predictions
#leaderboard.correct.vars <- leaderboard.features[,1:858]
ALSFRS.leader.pred=predict(prune.k.tree,newdata=leaderboard.feat.subset)
leaderboard.predictions$ALSFRS_slope <- ALSFRS.leader.pred
head(leaderboard.predictions)
```

We use **write.csv** function to write a CSV file in the contest format with the leaderboard subject predictions. 

```{r}
write.csv(leaderboard.predictions, file = "leaderboard_predictions_20151121_decision_tree_cv.csv",row.names=FALSE) # NEED TO MODIFY
```


